# Ax Prompt Flow - Where Prompts Are Saved and Used

## Overview
This document shows where Ax saves prompts to the database and where it uses prompts for the next iteration.

## Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. INITIAL PROMPT FETCH (runAxOptimization.ts)                 â”‚
â”‚    Line 69: getCurrentPrompt(promptApiBaseUrl)                 â”‚
â”‚    â†“                                                             â”‚
â”‚    Fetches latest prompt from database                          â”‚
â”‚    GET {PROMPT_API_BASE_URL}{PROMPT_ENDPOINT}                  â”‚
â”‚    â†“                                                             â”‚
â”‚    Returns: promptTemplate (string)                              â”‚
â”‚    â†“                                                             â”‚
â”‚    Stored in: currentPrompt variable                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. PASSED TO OPTIMIZER (runAxOptimization.ts)                   â”‚
â”‚    Line 91: optimizeBdcPrompt(currentPrompt, config)           â”‚
â”‚    â†“                                                             â”‚
â”‚    currentPrompt passed as initialPrompt parameter              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. OPTIMIZATION LOOP (axOptimizer.ts)                           â”‚
â”‚                                                                  â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚ ITERATION 0: Initial Evaluation                      â”‚    â”‚
â”‚    â”‚ Line 263: evaluatePrompt(currentPrompt, ...)        â”‚    â”‚
â”‚    â”‚ Uses: currentPrompt (from initialPrompt parameter)   â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                            â†“                                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚    â”‚ ITERATION 1, 2, 3... (Optimization Loop)             â”‚    â”‚
â”‚    â”‚                                                        â”‚    â”‚
â”‚    â”‚ Line 312-316: Ax generates candidate prompt          â”‚    â”‚
â”‚    â”‚   promptOptimizer.forward(llm, {                     â”‚    â”‚
â”‚    â”‚     currentPrompt: currentPrompt,  â† Uses in-memory   â”‚    â”‚
â”‚    â”‚     currentScore: lastIteration.score,                â”‚    â”‚
â”‚    â”‚     evaluationFeedback: feedback,                     â”‚    â”‚
â”‚    â”‚   })                                                   â”‚    â”‚
â”‚    â”‚   Returns: candidatePrompt                            â”‚    â”‚
â”‚    â”‚                                                        â”‚    â”‚
â”‚    â”‚ Line 328: Evaluate candidate                          â”‚    â”‚
â”‚    â”‚   evaluatePrompt(candidatePrompt, ...)                â”‚    â”‚
â”‚    â”‚                                                        â”‚    â”‚
â”‚    â”‚ Line 338: SAVE TO DATABASE â­                         â”‚    â”‚
â”‚    â”‚   postCandidatePrompt(promptApiBaseUrl, candidatePrompt, {â”‚
â”‚    â”‚     iteration: i,                                     â”‚    â”‚
â”‚    â”‚     score: evalResult.averageScore,                    â”‚    â”‚
â”‚    â”‚   })                                                   â”‚    â”‚
â”‚    â”‚   POST {PROMPT_API_BASE_URL}/agents/prompts            â”‚    â”‚
â”‚    â”‚                                                        â”‚    â”‚
â”‚    â”‚ Line 389: UPDATE IN-MEMORY VARIABLE âš ï¸                 â”‚    â”‚
â”‚    â”‚   currentPrompt = candidatePrompt;                     â”‚    â”‚
â”‚    â”‚   (NOT re-fetched from database!)                       â”‚    â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Locations

### 1. **Where Initial Prompt is Fetched**
**File:** `src/optimization/runAxOptimization.ts`
- **Line 69:** `getCurrentPrompt(promptApiBaseUrl)`
- **Function:** `src/agents/promptApi.ts` â†’ `getCurrentPrompt()`
- **Endpoint:** `GET {PROMPT_API_BASE_URL}{PROMPT_ENDPOINT}` (default: `/customer_discovery`)
- **Purpose:** Fetches the latest prompt from database at the start of optimization

### 2. **Where Candidate Prompts are Saved**
**File:** `src/optimization/axOptimizer.ts`
- **Line 338:** `postCandidatePrompt(promptApiBaseUrl, candidatePrompt, {...})`
- **Function:** `src/agents/promptApi.ts` â†’ `postCandidatePrompt()`
- **Endpoint:** `POST {PROMPT_API_BASE_URL}/agents/prompts`
- **When:** After each optimization iteration (after evaluation)
- **What's saved:**
  - `agentName`: From `AGENT_NAME` env var (default: "customer_discovery")
  - `promptTemplate`: The candidate prompt string
  - `metadata`: `{ iteration: i, score: evalResult.averageScore }`
- **Purpose:** Saves each candidate prompt to database (versioned)

### 3. **Where Prompt is Used for Next Iteration**
**File:** `src/optimization/axOptimizer.ts`
- **Line 313:** `currentPrompt: currentPrompt` (passed to Ax)
- **Line 389:** `currentPrompt = candidatePrompt;` (updated in-memory)
- **Important:** The code does NOT re-fetch from database between iterations
- **It uses:** The in-memory `currentPrompt` variable that gets updated after each iteration

## Important Notes

### âš ï¸ Current Behavior
- **Between iterations:** The code uses the in-memory `currentPrompt` variable
- **NOT re-fetched:** The latest prompt from the database is NOT fetched before each iteration
- **Only fetched once:** At the very start in `runAxOptimization.ts`

### âœ… What Gets Saved
- Each candidate prompt is saved to the database after evaluation
- The database will have all versioned prompts
- The latest version in the database will be used for the NEXT optimization RUN (not the next iteration)

### ğŸ”„ Flow Summary
1. **Start of run:** Fetch latest prompt from DB â†’ `currentPrompt`
2. **Each iteration:**
   - Use `currentPrompt` (in-memory) to generate next candidate
   - Evaluate candidate
   - Save candidate to DB (versioned)
   - Update `currentPrompt = candidatePrompt` (in-memory)
3. **Next run:** Will fetch the latest prompt from DB (which includes all saved candidates)

## If You Want to Use Latest DB Prompt Between Iterations

If you want to fetch the latest prompt from the database before each iteration (instead of using in-memory), you would need to:

1. Add a call to `getCurrentPrompt()` before line 312 in `axOptimizer.ts`
2. Update `currentPrompt` with the fetched value
3. This would ensure each iteration uses the actual latest version from the database

However, the current design uses in-memory prompts during a single optimization run, which is more efficient and ensures consistency within a run.

